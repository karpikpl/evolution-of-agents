{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60db279a",
   "metadata": {},
   "source": [
    "# Evolution of agents - LLM\n",
    "<img src=\"./images/baby_llm.png\" alt=\"Baby LLM\" style=\"max-height: 300px;\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b519ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Inference using Semantic Kernel\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import (\n",
    "    AzureAIInferenceChatCompletion,\n",
    "    AzureAIInferenceChatPromptExecutionSettings,\n",
    ")\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from azure.ai.inference.aio import ChatCompletionsClient\n",
    "import os\n",
    "from setup import get_credentials\n",
    "\n",
    "foundry_name = os.environ.get(\"AZURE_AI_FOUNDRY_NAME\", None)\n",
    "\n",
    "creds = get_credentials()\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=f\"https://{foundry_name}.services.ai.azure.com/models\",\n",
    "    credential=creds,\n",
    "    credential_scopes=[\"https://cognitiveservices.azure.com/.default\"],\n",
    ")\n",
    "\n",
    "request_settings = AzureAIInferenceChatPromptExecutionSettings()\n",
    "user_input = \"Tell me a joke.\"\n",
    "\n",
    "\n",
    "async def chat(\n",
    "    input: str,\n",
    "    system_message: str = \"You are a helpful assistant.\",\n",
    "    model: str = \"gpt-35-turbo\",\n",
    "):\n",
    "    chat_completion_service = AzureAIInferenceChatCompletion(\n",
    "        ai_model_id=model,\n",
    "        client=client,\n",
    "    )\n",
    "\n",
    "    chat_history = ChatHistory(system_message=system_message)\n",
    "    chat_history.add_user_message(user_input)\n",
    "\n",
    "    chat_history.add_user_message(input)\n",
    "    print(f\"User:> {input}\")\n",
    "\n",
    "    # Get the chat message content from the chat completion service.\n",
    "    response = await chat_completion_service.get_chat_message_content(\n",
    "        chat_history=chat_history,\n",
    "        settings=request_settings,\n",
    "    )\n",
    "    if response:\n",
    "        return f\"LLM:> {response}\"\n",
    "\n",
    "\n",
    "await chat(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"what date is today?\"\n",
    "await chat(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c82701a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"what are the mixing instructions for BUGBUSTERâ„¢ ULTRA INSECT ELIMINATOR?\"\n",
    "system_message = \"\"\"\n",
    "You are a helpful assistant that provides accurate and concise information for user queries. \n",
    "\n",
    "Do not guess. \n",
    "If you don't have detailed information, reply with 'I'm sorry, I don't have that information.'\n",
    "\"\"\"\n",
    "await chat(user_input, system_message=system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------- using 4.1 model\")\n",
    "await chat(user_input, system_message=system_message, model=\"gpt-4.1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
